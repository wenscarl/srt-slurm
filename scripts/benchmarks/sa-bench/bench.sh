#!/bin/bash
# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

# Example script adapted from https://github.com/kedarpotdar-nv/bench_serving/tree/dynamo-fix.

model_name="deepseek-ai/DeepSeek-R1"
model_path="/model/snapshots/25a138f28f49022958b9f2d205f9b7de0cdb6e18/"
head_node="localhost"
head_port=8000

n_prefill=$1
n_decode=$2
prefill_gpus=$3
decode_gpus=$4
total_gpus=$((prefill_gpus+decode_gpus))

source /scripts/utils/benchmark_utils.sh
work_dir="/scripts/benchmarks/sa-bench/"
cd $work_dir

chosen_isl=$5
chosen_osl=$6
concurrency_list=$7
IFS='x' read -r -a chosen_concurrencies <<< "$concurrency_list"
chosen_req_rate=$8
use_sglang_router=${9:-false}

echo "Config ${chosen_isl}; ${chosen_osl}; ${chosen_concurrencies[@]}; ${chosen_req_rate}; sglang_router=${use_sglang_router}"

wait_for_model_timeout=3600 # 1 hour
wait_for_model_check_interval=5 # check interval -> 5s
wait_for_model_report_interval=60 # wait_for_model report interval -> 60s

wait_for_model $head_node $head_port $n_prefill $n_decode $wait_for_model_check_interval $wait_for_model_timeout $wait_for_model_report_interval $use_sglang_router

# run a quick curl request against the model to do an accuracy spot check
curl http://${head_node}:${head_port}/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "deepseek-ai/DeepSeek-R1",
    "messages": [
      {
        "role": "user",
        "content": "is it possible to capture a cuda graph and move it to a new gpu?"
      }
    ],
    "stream": false,
    "max_tokens": 500
  }'

set -e
# Warmup the model with the same configuration as the benchmark
# Only difference between warmup and benchmark is request rate
for concurrency in "${chosen_concurrencies[@]}"
do
    echo "Warming up model with concurrency $concurrency"
    echo "$(date '+%Y-%m-%d %H:%M:%S')"
    num_prompts=$((concurrency * 5))
    set -x
    python3 -u benchmark_serving.py \
        --model ${model_name} --tokenizer ${model_path} \
        --host $head_node --port $head_port \
        --backend "dynamo" --endpoint /v1/completions \
        --disable-tqdm \
        --dataset-name random \
        --num-prompts "$num_prompts" \
        --random-input-len $chosen_isl \
        --random-output-len $chosen_osl \
        --random-range-ratio 0.8 \
        --ignore-eos \
        --request-rate 250 \
        --percentile-metrics ttft,tpot,itl,e2el \
        --max-concurrency "$concurrency"
    set +x
    echo "$(date '+%Y-%m-%d %H:%M:%S')"
done
set +e

result_dir="/logs/sa-bench_isl_${chosen_isl}_osl_${chosen_osl}"
mkdir -p $result_dir

set -e
for concurrency in "${chosen_concurrencies[@]}"
do
    num_prompts=$((concurrency * 5))
    echo "Running benchmark with concurrency: $concurrency and num-prompts: $num_prompts, writing to file ${result_dir}"
    result_filename="isl_${chosen_isl}_osl_${chosen_osl}_concurrency_${concurrency}_req_rate_${chosen_req_rate}_ctx${prefill_gpus}_gen${decode_gpus}.json"

    set -x
    echo "$(date '+%Y-%m-%d %H:%M:%S')"
    python3 -u benchmark_serving.py \
        --model ${model_name} --tokenizer ${model_path} \
        --host $head_node --port $head_port \
        --backend "dynamo" --endpoint /v1/completions \
        --disable-tqdm \
        --dataset-name random \
        --num-prompts "$num_prompts" \
        --random-input-len $chosen_isl \
        --random-output-len $chosen_osl \
        --random-range-ratio 0.8 \
        --ignore-eos \
        --request-rate ${chosen_req_rate} \
        --percentile-metrics ttft,tpot,itl,e2el \
        --max-concurrency "$concurrency" \
        --save-result --result-dir $result_dir --result-filename $result_filename
    set +x

    echo "$(date '+%Y-%m-%d %H:%M:%S')"
    echo "Completed benchmark with concurrency: $concurrency"
    echo "-----------------------------------------"
done
set +e
